{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Scraping & Analysis Program\n",
    "\n",
    "## 1. Gather Tweets with tweepy\n",
    "####     Input Search_Term (Search for tweets that contain the Search_Term)\n",
    "####     Input oldest_tweet  (Search for tweets with tweet ID's lower (older) than)\n",
    "\n",
    "## 2. Save Results\n",
    "####     Save TempDict to json file\n",
    "####     Save TempDict to csv file\n",
    "####     Save list of unique ID numbers to npy file\n",
    "\n",
    "## 3. Clean Results\n",
    "####     Perform Sentiment Analysis on Tweet Text\n",
    "####     Print specific attributes\n",
    "\n",
    "## 4. Convert Sentiment Analysis to Pandas DataFrame\n",
    "\n",
    "## 5. Scatter Plot of Sentiment Analysis\n",
    "\n",
    "## 6. Merge and munge json files\n",
    "#### Once tweets are saved to json files, open `Twitter_Munging_csv_Conversion.ipynb` for further processing and conversion to csv files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies & Keys\n",
    "\n",
    "## Load Dependencies:\n",
    " - tweepy (python library to access Twitter API)\n",
    " - json (display results in json format)\n",
    " - numpy (saving large dimensional arrays)\n",
    " - pandas (data frames)\n",
    " - vaderSentiment (Sentiment Analysis)\n",
    "\n",
    "## Keys\n",
    " - Create a Twitter developer account and create an app to create custom keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import tweepy\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "## Keys\n",
    "consumer_key = \"your key\"\n",
    "consumer_secret = \"your key\"\n",
    "access_token = \"your key\"\n",
    "access_token_secret = \"your key\"\n",
    "\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Gather tweets\n",
    "\n",
    "## Variable Inputs:\n",
    "\n",
    "### search_term\n",
    "-  Enter whatever custom search term you desire to search for...\n",
    "\n",
    "### oldest_tweet\n",
    "-  Enter in a tweet id for the most recent tweet id you want to search for, so all tweets gathered while executing will have a tweet id > oldest_tweet\n",
    "---------------------------------------------------------------------------------------------------------------------\n",
    "## Cell Outputs:\n",
    "\n",
    "### Print the number of tweets collected.\n",
    "-  If you are not hitting any query limits, this code should collect 5,000 tweets.\n",
    "\n",
    "### Print the total number of items in the TempDict list.\n",
    "-  This value should match the total number of tweets collected (counter).\n",
    "\n",
    "### Print the total number of unique tweet ids'.\n",
    "-  This value should also match the total number of tweets and number of items in the TempDict list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------\n",
    "# Execute Search\n",
    "#---------------------------------\n",
    "\n",
    "# Search for People Tweeting about Mark Hamill\n",
    "search_term = \"WomensWave\"\n",
    "\n",
    "# Create variable for holding the oldest tweet\n",
    "oldest_tweet = 1086719307894145023\n",
    "\n",
    "# List to hold unique IDs\n",
    "# unique_ids = []\n",
    "TempDict = []\n",
    "\n",
    "# Counter to keep track of the number of tweets retrieved\n",
    "counter = 0\n",
    "\n",
    "# Loop through 5 times (total of 5000 tweets)\n",
    "for x in range(50):\n",
    "\n",
    "    # Retrieve 100 most recent tweets -- specifying a max_id\n",
    "    public_tweets = api.search(search_term, \n",
    "                               count=100, \n",
    "                               result_type=\"recent\", \n",
    "                               max_id=oldest_tweet)\n",
    "\n",
    "    # Print Tweets\n",
    "    for tweet in public_tweets[\"statuses\"]:\n",
    "        tweet_id = tweet[\"id\"]\n",
    "        \n",
    "        if tweet_id not in unique_ids:\n",
    "            unique_ids.append(tweet_id)\n",
    "            TempDict.append(tweet)\n",
    "\n",
    "                        \n",
    "            # Increase counter by 1\n",
    "            counter += 1\n",
    "\n",
    "        # Reassign the the oldest tweet (i.e. the max_id)\n",
    "        # Subtract 1 so the previous oldest isn't included\n",
    "        # in the new search\n",
    "        oldest_tweet = tweet_id - 1\n",
    "print(f\"There were a total of {counter} tweets captured\")\n",
    "print(f\"There are a total of {len(TempDict)} objects in the dictionary\")\n",
    "print(f\"There are a total of {len(unique_ids)} unique ids\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# Verify Run\n",
    "########################\n",
    "\n",
    "# Number of Unique ID's Collected\n",
    "len(unique_ids)\n",
    "print(f\"Number of Unique IDs:            {len(unique_ids)}\")\n",
    "\n",
    "# Number of ID's Pulled in latest run\n",
    "print(f\"Number of ID's Pulled in Run:    {len(TempDict)}\")\n",
    "\n",
    "# Oldest Tweet Number\n",
    "print(f\"The current oldest tweet is:     {oldest_tweet}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Save Results\n",
    "\n",
    "### Save json file\n",
    "-  enter json file name in line 7 (\"filename.json\")\n",
    "\n",
    "### Save csv file\n",
    "-  enter csv file name in line 6 ('filename.csv')\n",
    "\n",
    "### Save id numbers\n",
    "-  enter npy file name ('filename.npy')\n",
    "\n",
    "### Print a single full tweet response\n",
    "-  You can change the integer in FirstEntries[0] to any number between 0 and the one number less than the number of tweets collected.\n",
    "- i.e., if 5,000 tweets were collected, you can change the 0 to any number between 0 - 4999, or pick a range of numbers (0:5). Each tweet response is very large, so you probably only want to print a single tweet response just to verify what has been collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "### Save TempDict as JSON File\n",
    "#########################\n",
    "\n",
    "import json\n",
    "json978 = json.dumps(TempDict)\n",
    "f = open(\"WomensWave12519_8.json\", \"w\")\n",
    "f.write(json978)\n",
    "f.close\n",
    "print(\"The json file was probably saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "### Create CSV File of DataFrame\n",
    "#########################\n",
    "\n",
    "TempDF = pd.DataFrame.from_dict(TempDict)\n",
    "TempDF.to_csv('WomensWave12519_8.csv')\n",
    "print(\"The json file was probably successfully saved as a CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "### Saving Unique ID Numbers to Numpy File\n",
    "#########################\n",
    "\n",
    "# unique_ids.tofile('WomensMarch_UniqueIds.dat')\n",
    "\n",
    "np.save('WomensWave2_UniqueIDs.npy', unique_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "### Print First Full Tweet Response to Inspect\n",
    "#########################\n",
    "\n",
    "FirstEntries = TempDict[0:10]\n",
    "FirstEntries[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Sentiment Analysis\n",
    "\n",
    "### Loading json files:\n",
    " - you can load as many data files as you want. Currently this notebook is configured to load 2 data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################\n",
    "#Dependencies for Cleaning Data\n",
    "##########################################################################################################\n",
    "\n",
    "# Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "from pprint import pprint\n",
    "Sentiments = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Enter_File_Name.json') as f:\n",
    "    data = json.load(f)\n",
    "print(f\"There are {len(data)} entries in data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Enter_2nd_File_name.json') as g:\n",
    "    data2 = json.load(g)\n",
    "\n",
    "print(f\"There are {len(data2)} entries in data2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge the two data lists (you can add as many data lists together as you want in this step)\n",
    "\n",
    "mergedlist = data + data2\n",
    "print(f\"There are {len(mergedlist)} entries in the merged list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Print off the 1st entry of the merged list\n",
    "\n",
    "pprint(mergedlist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# Begin Cleanning Process - Return is LOCAL PRINTING - NOT Saving to Files\n",
    "#########################\n",
    "\n",
    "list_num = 0\n",
    "\n",
    "#### Begin Loop through Tweets\n",
    "\n",
    "for x in TempDict:\n",
    "    print(f\"Tweet Number:   {list_num}\")\n",
    "##########################################################################################################\n",
    "\n",
    "    #### Created At:\n",
    "    created_at = x['created_at']\n",
    "    print(f\"Created At:     {created_at}\")\n",
    "##########################################################################################################\n",
    "\n",
    "    #### Tweet Text\n",
    "    Tweet_Text = x['text']\n",
    "    print(\"-\"*50)\n",
    "    print(f\"Tweet Text:     {Tweet_Text}\")\n",
    "    print(\"-\"*50)\n",
    "##########################################################################################################\n",
    "\n",
    "    #### Run Vader Analysis\n",
    "    results = analyzer.polarity_scores(x['text'])\n",
    "    compound = results['compound']\n",
    "    pos = results[\"pos\"]\n",
    "    neu = results[\"neu\"]\n",
    "    neg = results[\"neg\"]\n",
    "    \n",
    "    #### Add results to Sentiments List\n",
    "    Sentiments.append({\"Date\": tweet[\"created_at\"], \n",
    "                        \"compound\": compound,\n",
    "                        \"Positive\": pos,\n",
    "                        \"Negative\": neu,\n",
    "                        \"Neutral\": neg,\n",
    "                        \"Tweets Ago\": list_num})\n",
    "    print(\"Sentiment Analysis Results for Tweet Text:\")\n",
    "    print(f\"The Compound Score is:     {compound}\")\n",
    "    print(f\"The Positive Score is:     {pos}\")\n",
    "    print(f\"The Negative Score is:     {neu}\")\n",
    "    print(f\"The Neutral Score is:      {neg}\")\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "    #### ReTweet Count\n",
    "    try:\n",
    "        tweet_reTweet = x['retweet_count']\n",
    "    except:\n",
    "        print(f\"Re-Tweeted:     {retweet_count} times\")\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "    #### Favorite Count\n",
    "    try:\n",
    "        favorite_count = x['retweeted_status']['favorite_count']\n",
    "    except (IndexError, KeyError):\n",
    "        favorite_count = 'null'\n",
    "    \n",
    "##########################################################################################################\n",
    "\n",
    "    #### Hashtags\n",
    "    print(\"Hashtags Used:\")\n",
    "          \n",
    "    # Hashtag1\n",
    "    try: \n",
    "        hashtag1 = x['entities']['hashtags'][0]['text']\n",
    "    except IndexError:\n",
    "        hashtag1 = 'null'\n",
    "    print(f\"        HashTag1:     {hashtag1}\")\n",
    "          \n",
    "    # Hashtag2\n",
    "    try: \n",
    "        Hashtag2 = x['entities']['hashtags'][1]['text']\n",
    "    except IndexError:\n",
    "        Hashtag2 = 'null'\n",
    "    print(f\"        HashTag2:     {Hashtag2}\")\n",
    "          \n",
    "    # Hashtag3\n",
    "    try: \n",
    "        Hashtag3 = x['entities']['hashtags'][2]['text']\n",
    "    except IndexError:\n",
    "        Hashtag3 = 'null'\n",
    "    print(f\"        HashTag3:     {Hashtag3}\")\n",
    "        \n",
    "    # Hashtag4\n",
    "    try: \n",
    "        Hashtag4 = x['entities']['hashtags'][3]['text']\n",
    "    except IndexError:\n",
    "        Hashtag4 = 'null'\n",
    "    print(f\"        Hashtag4:     {Hashtag4}\")\n",
    "    \n",
    "##########################################################################################################\n",
    "\n",
    "    ##### Gathering Mentioned Screen Name and Names\n",
    "    print(\"Tweet Mentions:\")\n",
    "    # Mentioned Entry 1\n",
    "    try: \n",
    "        screenname1 = x['entities']['user_mentions'][0]['screen_name']\n",
    "    except IndexError:\n",
    "        screenname1 = 'null'\n",
    "    print(f\"        Mention 1:  screenname1:  {screenname1}\")\n",
    "    try: \n",
    "        name1 = x['entities']['user_mentions'][0]['name']\n",
    "    except IndexError:\n",
    "        name1 = 'null'\n",
    "    print(f\"        Mention 1:  name1:        {name1}\")\n",
    "\n",
    "    # Mentioned Entry 2\n",
    "    try: \n",
    "        screenname2 = x['entities']['user_mentions'][1]['screen_name']\n",
    "    except IndexError:\n",
    "        screenname2 = 'null'\n",
    "    print(f\"        Mention 2:  screenname2:  {screenname2}\")\n",
    "    try: \n",
    "        name2 = x['entities']['user_mentions'][1]['name']\n",
    "    except IndexError:\n",
    "        name2 = 'null'\n",
    "    print(f\"        Mention 2:  name2:        {name2}\")\n",
    "\n",
    "    # Mentioned Entry 3\n",
    "    try: \n",
    "        screenname3 = x['entities']['user_mentions'][2]['screen_name']\n",
    "    except IndexError:\n",
    "        screenname3 = 'null'\n",
    "    print(f\"        Mention 3:  screenname3:  {screenname3}\")\n",
    "    try: \n",
    "        name3 = x['entities']['user_mentions'][2]['name']\n",
    "    except IndexError:\n",
    "        name3 = 'null'\n",
    "    print(f\"        Mention 3:  name3:        {name3}\")\n",
    "\n",
    "    # Mentioned Entry 4\n",
    "    try: \n",
    "        screenname4 = x['entities']['user_mentions'][3]['screen_name']\n",
    "    except IndexError:\n",
    "        screenname4 = 'null'\n",
    "    print(f\"        Mention 4:  screenname4:  {screenname4}\")\n",
    "    try: \n",
    "        name4 = x['entities']['user_mentions'][3]['name']\n",
    "    except IndexError:\n",
    "        name4 = 'null'\n",
    "    print(f\"        Mention 4:  name4:        {name4}\")\n",
    "##########################################################################################################\n",
    "   \n",
    "    #### Begin User Profile Section\n",
    "    print(\"-\"*50)\n",
    "    print(\"Begin User Profile Section\")\n",
    "\n",
    "\n",
    "##########################################################################################################\n",
    "    #### Account name\n",
    "    User_Name = x['user']['name']\n",
    "    print(f\"User_Name:               {User_Name}\")\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "    #### Screen Name\n",
    "    Screen_Name = x['user']['screen_name']\n",
    "    print(f\"Screen Name:             {Screen_Name}\")\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "    #### User Description\n",
    "    User_Description = x['user']['description']\n",
    "    print(f\"User Description:        {User_Description}\")\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "    #### User location\n",
    "    try:\n",
    "        User_Location = x['user']['location']\n",
    "    except:\n",
    "        User_Location = 'null'\n",
    "    print(f\"User Location:           {User_Location}\")\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "    #### User Following Count (how many people are they following)\n",
    "    User_FollowersCt = x['user']['followers_count']\n",
    "    print(f\"User Followers Count:    {User_FollowersCt}\")\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "    #### User Followed Count (how many people are following the user)\n",
    "    User_FriendsCt = x['user']['friends_count']\n",
    "    print(f\"User Friends Count:      {User_FriendsCt}\")\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "    #### User Verified\n",
    "    User_Verified = x['user']['verified']\n",
    "    print(f\"User Verfied:            {User_Verified}\")\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "    #### User_Geo\n",
    "    try:\n",
    "        User_Geo = x['geo']\n",
    "    except:\n",
    "        User_Geo = 'null'\n",
    "    print(f\"User Geo:                {User_Geo}\")\n",
    "\n",
    "########################################################################################################## \n",
    "\n",
    "    #### User_Place\n",
    "    try:\n",
    "        User_Place = x['place']\n",
    "    except:\n",
    "        User_Place = 'null'\n",
    "    print(f\"User Place:              {User_Place}\")\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "    #### Begin Meta Section\n",
    "    print(\"-\"*50)\n",
    "    print(\"Begin Meta Section\")\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "    #### Tweet_ID\n",
    "    Tweet_ID = x['id']\n",
    "    print(f\"Tweet ID:                {Tweet_ID}\")\n",
    "    \n",
    "##########################################################################################################\n",
    "\n",
    "    #### Tweet_ID_Str\n",
    "    Tweet_ID_str = x['id_str']\n",
    "    print(f\"Tweet ID str:            {Tweet_ID_str}\")\n",
    "    \n",
    "##########################################################################################################\n",
    "\n",
    "    #### ReTweet_ID\n",
    "    try:\n",
    "        ReTweet_ID = x['retweeted_status']['id']\n",
    "    except:\n",
    "        ReTweet_ID = 'null'\n",
    "    print(f\"ReTweet_ID:              {ReTweet_ID}\")\n",
    "    \n",
    "##########################################################################################################\n",
    "\n",
    "    #### ReTweet_ID_Str\n",
    "    try:\n",
    "        ReTweet_ID_str = x['retweeted_status']['id_str']\n",
    "    except:\n",
    "        ReTweet_ID_str = 'null'\n",
    "    print(f\"ReTweet_ID str:          {ReTweet_ID_str}\")\n",
    "    \n",
    "##########################################################################################################\n",
    "\n",
    "    #### Coordinates\n",
    "    try:\n",
    "        coordinates = x['coordinates']\n",
    "    except:\n",
    "        coordinates = 'null'\n",
    "    print(f\"Coordinates:             {coordinates}\")\n",
    "    \n",
    "##########################################################################################################\n",
    "    \n",
    "    \n",
    "    ## Print end of tweet ---\n",
    "    print(\"*\"*75)\n",
    "    list_num = list_num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "#### Post Cleaning Analysis\n",
    "#############################\n",
    "\n",
    "# How many entries in the Sentiment List\n",
    "print(f\"Number of items in Sentiments List:     {len(Sentiments)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "#### Convert Sentiment List into DF\n",
    "############################\n",
    "\n",
    "sentiments_pd = pd.DataFrame.from_dict(Sentiments)\n",
    "sentiments_pd.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "#### Summary Stats of Sentiments DF\n",
    "############################\n",
    "\n",
    "print(f\"The Median Compound Score is:    {sentiments_pd['compound'].median()}\")\n",
    "print(f\"The Median Negative Score is:    {sentiments_pd['Negative'].median()}\")\n",
    "print(f\"The Median Positive Score is:    {sentiments_pd['Positive'].median()}\")\n",
    "print(f\"The Median Neutral Score is:    {sentiments_pd['Neutral'].median()}\")\n",
    "\n",
    "print(f\"The Mean Compound Score is:    {sentiments_pd['compound'].mean()}\")\n",
    "print(f\"The Mean Negative Score is:    {sentiments_pd['Negative'].mean()}\")\n",
    "print(f\"The Mean Positive Score is:    {sentiments_pd['Positive'].mean()}\")\n",
    "print(f\"The Mean Neutral Score is:    {sentiments_pd['Neutral'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################\n",
    "#Dependencies Plotting with Matplotlib\n",
    "##########################################################################################################\n",
    "\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from matplotlib.pyplot import figure\n",
    "style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot\n",
    "fig = plt.figure(figsize=(16,10))\n",
    "x_vals = sentiments_pd[\"Tweets Ago\"]\n",
    "y_vals = sentiments_pd[\"compound\"]\n",
    "plt.scatter(x_vals,\n",
    "         y_vals,\n",
    "         marker=\"o\",\n",
    "         linewidth=0.5,\n",
    "         alpha=0.8        )\n",
    "\n",
    "# # Incorporate the other graph properties\n",
    "now = datetime.now()\n",
    "now = now.strftime(\"%Y-%m-%d %H:%M\")\n",
    "plt.title(f\"Sentiment Analysis of Tweets ({now}) for {search_term}\")\n",
    "plt.xlim([x_vals.max(),x_vals.min()]) #Bonus\n",
    "plt.ylabel(\"Tweet Polarity\")\n",
    "plt.xlabel(\"Tweets Ago\")\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "#### Save Figure\n",
    "###########################\n",
    "\n",
    "plt.savefig('test.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "#################################################################################\n",
    "####### NOT for running - this is notes and the legand\n",
    "#################################################################################\n",
    "\n",
    "#     tweet['created_at']                               # Time Stamp of when tweet was created\n",
    "#     tweet['id']                                       # tweet id Object (number)\n",
    "#     tweet['id_str']                                   # tweet id String format (number)\n",
    "#     tweet['text']                                     # text of tweet\n",
    "#     tweet['entities']['hashtags']['text']             # hashtags taken\n",
    "#     tweet['entities']['user_mentions']['screen_name'] # screen name of person mentioned\n",
    "#     tweet['entities']['user_mentions']['name']        # name of person mentioned\n",
    "#     tweet['user']['id']                               # id (object) of account user\n",
    "#     tweet['user']['name']                             # name of account user\n",
    "#     tweet['user']['screen_name']                      # Screen name of person\n",
    "#     tweet['user']['location']                         # string, user input of their location\n",
    "#     tweet['user']['description']                      # description of the account user\n",
    "#     tweet['user']['followers_count']                  # number of accounts user is following\n",
    "#     tweet['user']['friends_count']                    # number of accounts user is friends with\n",
    "#     tweet['user']['verified']                         # is the account user 'verified'\n",
    "#     tweet['geo']                                      # is geo null or on\n",
    "#     tweet['coordinates']                              # coordinates or null\n",
    "#     tweet['place']                                    # tweet place description or null\n",
    "#     tweet['retweeted_status']['id']                   # Original tweet id number object\n",
    "#     tweet['retweeted_status']['id_str']               # Original tweet id number string\n",
    "#     tweet['retweet_count']                            # number of times an original tweet has been retweeted\n",
    "#     tweet['retweeted_status']['favorite_count']       # number of times a tweet has been favorited"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
